{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import the Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Python libraries\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Libraries for data manipulation and visualization\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Libraries for detection and classification\n",
    "from mtcnn import MTCNN \n",
    "from keras_facenet import FaceNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Set Aquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturing data set for new user from camera using MTCNN detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BELOM BERES (LATER)\n",
    "\n",
    "def captureImage():\n",
    "    # initialize the MTCNN detector\n",
    "    detector = MTCNN()\n",
    "\n",
    "    # initialize the video capture object for the default camera\n",
    "    cam = cv2.VideoCapture(0)\n",
    "\n",
    "    # initialize catured frame variable\n",
    "\n",
    "    while True:\n",
    "        # read the frame from the camera\n",
    "        ret, frame = cam.read()\n",
    "\n",
    "        # detect faces using MTCNN\n",
    "        faces = detector.detect_faces(frame)\n",
    "\n",
    "        # draw bounding boxes around the faces\n",
    "        for face in faces:\n",
    "            x, y, w, h = face['box']\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "\n",
    "        # show the resulting frame\n",
    "        cv2.imshow('Real-time Face Detection', frame)\n",
    "\n",
    "        # press 'q' key to exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # release the video capture object and close all windows\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. MTCNN Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract faces from captured image using MTCNN and resize the image into 160x160. After that, do flip and contrast stretching to resized image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FACELOADING:\n",
    "    def __init__(self, directory):\n",
    "        self.directory = directory\n",
    "        self.target_size = (160, 160)\n",
    "        self.X = []\n",
    "        self.Y = []\n",
    "        self.detector = MTCNN()\n",
    "\n",
    "    def extract_faces(self, filename):\n",
    "        img = cv2.imread(filename)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        hasil_deteksi = self.detector.detect_faces(img)\n",
    "\n",
    "        # Getting x, y, w, h from image 'box'\n",
    "        x, y, w, h = hasil_deteksi[0]['box']\n",
    "        x, y, w, h = abs(x), abs(y), abs(w), abs(h)\n",
    "\n",
    "        # Draw rectangle box on detected face\n",
    "        img = cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 255), 10)\n",
    "\n",
    "        wajah = img[y:y + h, x:x + w]\n",
    "        wajah_arr = cv2.resize(wajah, self.target_size)\n",
    "        return wajah_arr\n",
    "\n",
    "    def load_faces(self, dir, class_label):\n",
    "        FACES = []\n",
    "        Y = []\n",
    "        for im_name in os.listdir(dir):\n",
    "            try:\n",
    "                path = os.path.join(dir, im_name)\n",
    "                single_face = self.extract_faces(path)\n",
    "                FACES.append(single_face)\n",
    "                Y.append(class_label)\n",
    "\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        return FACES, Y\n",
    "\n",
    "    def parse_filename(self, filename):\n",
    "        # Mengambil NIM dan Nama dari nama file dengan pola \"NIM_Nama_i.jpg\"\n",
    "        nim, nama, _ = filename.split('_')\n",
    "        return nim, nama\n",
    "\n",
    "    def load_classes_after_augmentation(self, output_folder=None):\n",
    "        # Inisialisasi kembali X dan Y\n",
    "        X = []\n",
    "        Y = []\n",
    "\n",
    "        # Membuat subdirektori yang belum ada\n",
    "        if output_folder:\n",
    "            for class_label in set(self.Y):  # Menggunakan set(Y) untuk mendapatkan kelas unik\n",
    "                class_dir = os.path.join(output_folder, class_label)\n",
    "                if not os.path.exists(class_dir):\n",
    "                    os.makedirs(class_dir)\n",
    "\n",
    "        for sub_dir in os.listdir(self.directory):\n",
    "            path = os.path.join(self.directory, sub_dir)\n",
    "            FACES, labels = self.load_faces_after_augmentation(path, sub_dir, output_folder=output_folder)\n",
    "            X.extend(FACES)\n",
    "            Y.extend(labels)\n",
    "\n",
    "        return X, Y\n",
    "\n",
    "    def load_faces_after_augmentation(self, dir, class_label, output_folder=None):\n",
    "        FACES = []\n",
    "        Y = []\n",
    "        for i, im_name in enumerate(os.listdir(dir)):\n",
    "            try:\n",
    "                path = os.path.join(dir, im_name)\n",
    "                single_face = self.extract_faces(path)\n",
    "                FACES.append(single_face)\n",
    "                Y.append(class_label)\n",
    "\n",
    "                nim, nama = self.parse_filename(im_name)\n",
    "\n",
    "                # Check if the output folder exists for the current class label\n",
    "                class_output_folder = os.path.join(output_folder, class_label)\n",
    "                if not os.path.exists(class_output_folder):\n",
    "                    os.makedirs(class_output_folder)    \n",
    "\n",
    "                # Jika ingin melakukan augmentasi pada citra di sini, tambahkan proses augmentasi di sini.\n",
    "                flipped_face = cv2.flip(single_face, 1)  # 1 for horizontal flip\n",
    "                FACES.append(flipped_face)\n",
    "                Y.append(class_label)\n",
    "\n",
    "                contrast_stretched_face = self.contrast_stretching(single_face)\n",
    "                FACES.append(contrast_stretched_face)\n",
    "                Y.append(class_label)\n",
    "\n",
    "                if output_folder:\n",
    "                    index_start = 1 + i * 3\n",
    "\n",
    "                    # Simpan citra dengan penamaan yang mengikuti nim dan nama\n",
    "                    original_filename = f\"{nim}_{nama}_{index_start}.jpg\"\n",
    "                    output_path_original = os.path.join(output_folder, class_label, original_filename)\n",
    "                    cv2.imwrite(output_path_original, cv2.cvtColor(single_face, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "                    flipped_filename = f\"{nim}_{nama}_{index_start + 1}.jpg\"\n",
    "                    output_path_flip = os.path.join(output_folder, class_label, flipped_filename)\n",
    "                    cv2.imwrite(output_path_flip, cv2.cvtColor(flipped_face, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "                    stretched_filename = f\"{nim}_{nama}_{index_start + 2}.jpg\"\n",
    "                    output_path_stretch = os.path.join(output_folder, class_label, stretched_filename)\n",
    "                    cv2.imwrite(output_path_stretch, cv2.cvtColor(contrast_stretched_face, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        return FACES, Y\n",
    "\n",
    "    def contrast_stretching(self, image):\n",
    "        # Compute minimum and maximum pixel values for each channel\n",
    "        min_val = np.min(image, axis=(0, 1))\n",
    "        max_val = np.max(image, axis=(0, 1))\n",
    "\n",
    "        # Perform contrast stretching for each channel\n",
    "        stretched = (image - min_val) * (255.0 / (max_val - min_val))\n",
    "        stretched = np.clip(stretched, 0, 255).astype(np.uint8)\n",
    "\n",
    "        return stretched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the user if they want to use the existing dataset or capture new images\n",
    "use_existing_data = input(\"Do you want to use the last existing dataset (y/n)? \")\n",
    "faces_dataset_filename = \"dataframe_and_model_files/loadedfaces.npz\"\n",
    "\n",
    "# If the user wants to use the existing dataset, load the dataset from the .npz file\n",
    "if use_existing_data.lower() == 'y':\n",
    "    # Loads the faces and labels from the compressed .npz file.\n",
    "    loaded_data = np.load(\"dataframe_and_model_files/loadedfaces.npz\")\n",
    "    X = loaded_data[\"X\"]\n",
    "    Y = loaded_data[\"Y\"]\n",
    "\n",
    "    print(f\"Faces Dataset successfully loaded from {faces_dataset_filename}\")\n",
    "    print(f\"===============================================\")\n",
    "\n",
    "    print(f\"Unique Labels After Augmentation: {set(Y)}\")\n",
    "    print(f'Total Images in Array After Augmentation: {len(X)} images')\n",
    "\n",
    "if use_existing_data.lower() == 'n':\n",
    "    # Gunakan kelas FACELOADING dengan folder direktori \"capturedfaces\"\n",
    "    face_loader = FACELOADING(\"capturedfaces\")\n",
    "    X, Y = face_loader.load_classes_after_augmentation(output_folder=\"datawajah\")\n",
    "\n",
    "    print(f\"Unique Labels After Augmentation: {set(Y)}\")\n",
    "    print(f'Total Images in Array After Augmentation: {len(X)} images')\n",
    "\n",
    "    # Saves the loaded faces and labels into a compressed .npz file\n",
    "    np.savez_compressed(faces_dataset_filename, X=X, Y=Y)\n",
    "    print()\n",
    "    print(\"File loaded and saved to dataframe_and_model_files/loadedfaces.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataframe that containing available images from extracted faces and checking total files in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe():\n",
    "    # Initialize main dataset folder\n",
    "    dataset_folder = \"datawajah\"\n",
    "    root_folder = dataset_folder\n",
    "\n",
    "    data = []\n",
    "  \n",
    "    # Iterate through the main folder and subfolders\n",
    "    for root, dirs, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "        # Get the subfolder name (classes)\n",
    "            classes = os.path.basename(root)\n",
    "\n",
    "            # Get the full path of the image\n",
    "            image_path = os.path.join(classes, file)\n",
    "\n",
    "            # Add data to the list\n",
    "            data.append({'Classes': classes, 'File Name': file, 'Image Path': image_path})\n",
    "\n",
    "    # Create a dataframe from the data list\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Save the dataframe to an Excel file\n",
    "    excel_file_name = 'dataframe_and_model_files/faces_train_data.xlsx'\n",
    "    df.to_excel(excel_file_name, index=False)\n",
    "\n",
    "    print(\"Dataframe successfully saved to\", excel_file_name)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_images_per_class(df):\n",
    "    # Function to calculate the total number of files in a folder.\n",
    "    def total_file(classes):\n",
    "        return len(df[df['Classes'] == classes].values)\n",
    "\n",
    "    # Iterate through unique classes and print the total number of files for each class\n",
    "    unique_classes = df['Classes'].unique()\n",
    "    print(\"Total number of images in each class :\")\n",
    "    for classes in unique_classes:\n",
    "        count = total_file(classes)\n",
    "        print(f\"'{classes}': {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframe\n",
    "df = create_dataframe()\n",
    "\n",
    "# Calculate and print the total number of images in each class\n",
    "total_images_per_class(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. FaceNet Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embed the dataset to 512 dimension image (1x1x512) and save it into .npz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = FaceNet()\n",
    "\n",
    "def get_embedding(face_image):\n",
    "    face_image = face_image.astype('float32') # 3D(160x160x3)\n",
    "    face_image = np.expand_dims(face_image, axis=0) # 4D(Nonex160x160x3)\n",
    "    \n",
    "    yhat = embedder.embeddings(face_image)\n",
    "\n",
    "    return yhat[0] #512D image (1x1x152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_data_loaded = input(\"Do you want to load last saved embedded data from the file 'dataframe_and_model_files/embedded_dataset.npz' (y/n)? \")\n",
    "embedded_file_name = \"dataframe_and_model_files/embedded_dataset.npz\"\n",
    "\n",
    "if embedded_data_loaded.lower() == 'y':\n",
    "    # Load the embedded data from the npz file\n",
    "    loaded_data = np.load('dataframe_and_model_files/embedded_dataset.npz', allow_pickle=True)\n",
    "    EMBEDDED_X = loaded_data['arr_0']\n",
    "    Y = loaded_data['arr_1']\n",
    "\n",
    "    # Reload the arrays of original X\n",
    "    loaded_data = np.load(\"dataframe_and_model_files/loadedfaces.npz\")\n",
    "    X = loaded_data[\"X\"]\n",
    "\n",
    "    print(f\"Embedded dataset successfully loaded from {embedded_file_name}\")\n",
    "    print()\n",
    "    print(f\"Unique Labels: {set(Y)}\")\n",
    "    print(f'Total Embedded Images in Array: {len(EMBEDDED_X)}')\n",
    "    \n",
    "if embedded_data_loaded.lower() == 'n':\n",
    "    # Embedding the datasets and save it to the npz file\n",
    "    EMBEDDED_X = []\n",
    "\n",
    "    for face_image in X:\n",
    "        EMBEDDED_X.append(get_embedding(face_image))\n",
    "\n",
    "    EMBEDDED_X = np.asarray(EMBEDDED_X)\n",
    "    np.savez_compressed(embedded_file_name, EMBEDDED_X, Y)\n",
    "    print(\"Embedded dataset successfully saved to\", embedded_file_name)\n",
    "    print(\"===============================================\")\n",
    "    print(f\"Unique Labels: {set(Y)}\")\n",
    "    print(f'Total Embedded Images in Array: {len(EMBEDDED_X)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a few random indices\n",
    "num_display_samples = 5\n",
    "sample_indices = random.sample(range(len(EMBEDDED_X)), num_display_samples)\n",
    "\n",
    "# Display the sample images with their corresponding labels and embeddings\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i, index in enumerate(sample_indices):\n",
    "    plt.subplot(2, num_display_samples, i + 1)\n",
    "    plt.imshow(X[index])\n",
    "    plt.title(f\"Original: {Y[index]}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, num_display_samples, i + num_display_samples + 1)\n",
    "    plt.imshow(EMBEDDED_X[index].reshape((1, -1)))\n",
    "    plt.title(f\"Embedded: {Y[index]}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correspondence between images in 'X' and labels in 'Y'\n",
    "for i in range(len(X)):\n",
    "    print(f\"Label: {Y[i]}, File Name: {df['File Name'].iloc[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SVM Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the data from the npz file\n",
    "loaded_data = np.load('dataframe_and_model_files/embedded_dataset.npz', allow_pickle=True)\n",
    "X = loaded_data['arr_0']\n",
    "Y = loaded_data['arr_1']\n",
    "\n",
    "# Perform Stratified K-fold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize arrays to store the train and test embeddings and labels\n",
    "X_train_folds = []\n",
    "X_test_folds = []\n",
    "y_train_folds = []\n",
    "y_test_folds = []\n",
    "\n",
    "# Perform Stratified K-fold cross validation\n",
    "for train_index, test_index in skf.split(X, Y):\n",
    "    X_train_folds.append(X[train_index])\n",
    "    X_test_folds.append(X[test_index])\n",
    "    y_train_folds.append(np.take(Y, train_index))\n",
    "    y_test_folds.append(Y[test_index])\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm_classifier = svm.SVC(kernel='linear', probability=True)\n",
    "\n",
    "# Initialize empty lists to store the train and test predictions\n",
    "train_predictions = []\n",
    "test_predictions = []\n",
    "\n",
    "# Store the trained model and test predictions for each fold\n",
    "fold_models = []\n",
    "fold_test_predictions = []\n",
    "model_filename = \"dataframe_and_model_files/mtcnn_svm_model_facercognition.npz\"\n",
    "\n",
    "for i in range(skf.get_n_splits()):\n",
    "    svm_classifier.fit(X_train_folds[i], y_train_folds[i])\n",
    "    train_predictions.append(svm_classifier.predict(X_train_folds[i]))\n",
    "    test_predictions.append(svm_classifier.predict(X_test_folds[i]))\n",
    "\n",
    "    # Save the trained model, test predictions, and true labels for this fold\n",
    "    fold_models.append(svm_classifier)\n",
    "    fold_test_predictions.append(np.vstack((test_predictions[i], y_test_folds[i])).T)\n",
    "\n",
    "# Save the models, test predictions, and true labels to a file\n",
    "np.savez(model_filename, models=fold_models, test_predictions=fold_test_predictions)\n",
    "\n",
    "# Calculate the accuracy, precision, recall, and F1 score for each fold\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "for i in range(skf.get_n_splits()):\n",
    "    accuracies.append(accuracy_score(y_train_folds[i], train_predictions[i]))\n",
    "    precisions.append(precision_score(y_train_folds[i], train_predictions[i], average='weighted'))\n",
    "    recalls.append(recall_score(y_train_folds[i], train_predictions[i], average='weighted'))\n",
    "    f1_scores.append(f1_score(y_train_folds[i], train_predictions[i], average='weighted'))\n",
    "    print(f'Fold {i+1} - Train Accuracy: {accuracies[i]*100:.2f}%, '\n",
    "          f'Precision: {precisions[i]*100:.2f}%%, '\n",
    "          f'Recall: {recalls[i]*100:.2f}%%, '\n",
    "          f'F1 Score: {f1_scores[i]*100:.2f}%')\n",
    "    print(f'Fold {i+1} - Test Accuracy: {accuracy_score(y_test_folds[i], test_predictions[i])*100:.2f}%')\n",
    "    print()\n",
    "\n",
    "# Calculate the average accuracy, precision, recall, and F1 score\n",
    "avg_accuracy = np.mean(accuracies)\n",
    "avg_precision = np.mean(precisions)\n",
    "avg_recall = np.mean(recalls)\n",
    "avg_f1_score = np.mean(f1_scores)\n",
    "\n",
    "print(f'Average Accuracy: {avg_accuracy*100}%')\n",
    "print(f'Average Precision: {avg_precision*100}%')\n",
    "print(f'Average Recall: {avg_recall*100}%')\n",
    "print(f'Average F1 Score: {avg_f1_score*100}%')\n",
    "\n",
    "# Calculate the confusion matrix for each fold\n",
    "confusion_matrices = []\n",
    "for i in range(skf.get_n_splits()):\n",
    "    y_true = y_test_folds[i]\n",
    "    y_pred = test_predictions[i]\n",
    "    confusion_mtx = confusion_matrix(y_true, y_pred)\n",
    "    confusion_matrices.append(confusion_mtx)\n",
    "\n",
    "# Sum up the confusion matrices\n",
    "confusion_mtx = np.sum(confusion_matrices, axis=0)\n",
    "\n",
    "# Get the unique classes from the true labels\n",
    "classes = np.unique(y_true)\n",
    "\n",
    "# Create a confusion matrix with labels instead of integer values\n",
    "confusion_mtx_labels = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "\n",
    "# Plot the confusion matrix with labels instead of integer values\n",
    "sns.heatmap(confusion_mtx_labels, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "\n",
    "# Set the xticklabels and yticklabels to the unique classes\n",
    "plt.xticks(ticks=range(len(classes)), labels=classes)\n",
    "plt.yticks(ticks=range(len(classes)), labels=classes)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from mtcnn import MTCNN\n",
    "import joblib\n",
    "\n",
    "# Load MTCNN face detection model\n",
    "detector = MTCNN()\n",
    "\n",
    "# Load saved model\n",
    "model_filename = \"dataframe_and_model_files/mtcnn_svm_model_facercognition.npz\"\n",
    "model = np.load(model_filename)\n",
    "\n",
    "# Initialize the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize a variable to keep track of the start time\n",
    "start_time = time.time()\n",
    "\n",
    "while True:\n",
    "    # Capture frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Calculate the elapsed time\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    # If 10 seconds have elapsed, break the loop\n",
    "    if elapsed_time > 10:\n",
    "        break\n",
    "\n",
    "# Release the camera\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Capture the frame at the 10th second\n",
    "while elapsed_time < 10:\n",
    "    # Capture frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Calculate the elapsed time\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "# Detect faces in the frame\n",
    "faces = detector.detect_faces(frame)\n",
    "\n",
    "# Initialize empty list to store the detected faces\n",
    "detected_faces = []\n",
    "\n",
    "# Extract detected faces\n",
    "for face in faces:\n",
    "    x, y, w, h = face['box']\n",
    "    detected_faces.append(frame[y:y+h, x:x+w])\n",
    "\n",
    "# Recognize faces\n",
    "recognized_faces = []\n",
    "for face in detected_faces:\n",
    "    face = cv2.resize(face, (160, 160))\n",
    "    face = np.expand_dims(face, axis=0)\n",
    "    face = face.astype('float32')\n",
    "    pred = model.predict(face)\n",
    "    recognized_faces.append(pred[0])\n",
    "\n",
    "# Print recognized faces\n",
    "print(recognized_faces)\n",
    "\n",
    "# Release the camera\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# Save the trained model to a file\n",
    "joblib.dump(svm_classifier, 'svm_model.joblib.gz', compress=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now add the program code to open the camera and then perform face recognition using the model that has been created, create a square on the detected face and display the class of the face, as well as the accuracy of the recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Re-Training Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
